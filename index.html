<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haiyang Guo</title>

    <meta name="author" content="Haiyang Guo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="basic/icon.png" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>
  
<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <!-- Basic Information -->
          <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <!-- Basic Information -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Haiyang Guo
                </p>
                <p>I'm currently a first-year Ph.D. student at <a href="https://sais.ucas.ac.cn/index.php/zh/">School of Advanced Interdisciplinary Sciences, University of Chinese Academy of Sciences</a>, enrolled in the integrated M.S.-Ph.D. program, supervised by Prof. <a href="https://scholar.google.com/citations?hl=en&user=xl11SEMAAAAJ">Xu-Yao Zhang</a> and Prof. <a href="https://scholar.google.com/citations?hl=en&user=8r3y8IMAAAAJ">Cheng-Lin Liu</a>. I previously studied at the <a href="http://english.ia.cas.cn/">Institute of Automation, Chinese Academy of Sciences</a>, under the same supervision.
                </p>
                <p>
                  Before that, I obtained my Bachlor degree from <a href="https://en.ustb.edu.cn/">University of Science and Technology Beijing</a>, majoring in Artificial Intelligence.
                </p>
                <p>
                  My research focuses on continual learning for real-world applications, with an emphasis on multimodal continual learning and federated continual learning. I am also interested in other downstream tasks of MLLMs, including memory systems, model merging, and hallucination mitigation.
                 </p>
                <p style="text-align:center">
                  <a href="mailto:guohaiyang2023@ia.ac.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com.hk/citations?user=p1eW_uwAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Ghy0501/">Github</a> &nbsp;/&nbsp;
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="basic/guohaiyang.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="basic/guohaiyang.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <!--/ Basic Information -->

          <!-- Education -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Education</h2>
                <!-- ul style="list-style-type: disc; padding: 0;"-->
                <ul style="list-style-type: disc; padding-left: 20px;">
				  <li style="margin: 5px;">
                    <b>Ph.D.</b> @ <b><a href="https://sais.ucas.ac.cn/index.php/zh/">SAIS, University of Chinese Academy of Sciences</a></b>, 2025.02-2028.06 (expected)
                    <br><span>Advisor: Prof. <a href="https://scholar.google.com/citations?hl=en&user=xl11SEMAAAAJ">Xu-Yao Zhang</a> and Prof. <a href="https://scholar.google.com/citations?hl=en&user=8r3y8IMAAAAJ">Cheng-Lin Liu</a></span>
                  </li>
                  <li style="margin: 5px;">
                    <b>M.S.</b> @ <b><a href="http://english.ia.cas.cn/">MAIS, Institute of Automation, Chinese Academy of Sciences</a></b>, 2023.09-2025.02
                    <br><span>Advisor: Prof. <a href="https://scholar.google.com/citations?hl=en&user=xl11SEMAAAAJ">Xu-Yao Zhang</a> and Prof. <a href="https://scholar.google.com/citations?hl=en&user=8r3y8IMAAAAJ">Cheng-Lin Liu</a></span>
                  </li>
                  <li style="margin: 5px;">
                    <b>B.S.</b> @ <b><a href="https://ai.ustb.edu.cn/">SIST, University of Science and Technology Beijing</a></b>, 2019.09-2023.06
                  </li>
                </ul>
              </td>
            </tr>
          </tbody></table>
          <!--/ Education -->

          <!-- News -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <!-- ul style="list-style-type: disc; padding: 0;"-->
                <ul style="list-style-type: disc; padding-left: 20px;">
		  <li style="margin: 5px;">
                    <b>[2025.05]</b> One paper (FCIT) is accepted to <a href="https://iccv.thecvf.com/">ICCV 2025</a>. Congratulations to all my collaborators!
                  </li>
                  <li style="margin: 5px;">
                    <b>[2025.05]</b> Two papers (HiDe-LLaVA, ChartEdit) are accepted to <a href="https://2025.aclweb.org/calls/main_conference_papers">ACL 2025</a>. Congratulations to all my collaborators!
                  </li>
<!-- 		<li style="margin: 5px;">
                    <b>[2025.02]</b> One paper (MambaIC) is accepted to <a href="https://cvpr.thecvf.com/Conferences/2025">CVPR 2025</a>!!
                  </li> -->
                  <li style="margin: 5px;">
                    <b>[2025.01]</b> One paper (Local-Prompt) is accepted to <a href="https://iclr.cc/">ICLR 2025</a>.
                  </li>
                </ul>
              </td>
            </tr>
            </tbody></table>
          <!--/ News -->

          
          <!-- Publications -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Publications</h2>
              <p>
                * indicates equal contribution
              </p>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!--/ Publications -->
          
	 <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ICCV25_FCIT.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">Federated Continual Instruction Tuning</span>
              <br>
               Haiyang Guo, <strong>Fanhu Zeng</strong>, Fei Zhu, Wenzhuo Liu, Da-Han Wang, Jian Xu, Xu-Yao Zhang, Cheng-Lin Liu
              <br>
	      <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
	       <br>
              <a href="https://arxiv.org/abs/2503.12897">arXiv</a> / <a href="https://github.com/Ghy0501/FCIT">Code</a>
              <br>
            </td>
          </tr>
		  
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ACL25_HiDe-LLaVA.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model</span>
              <br>
               Haiyang Guo*, <strong>Fanhu Zeng*</strong>, Ziwei Xiang, Fei Zhu, Da-Han Wang, Xu-Yao Zhang, Cheng-Lin Liu
              <br>
              <em>Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>)</em>, 2025
              <br>
              <a href="https://aclanthology.org/2025.acl-long.666">Paper</a> / <a href="https://arxiv.org/abs/2503.12941">arXiv</a> / <a href="https://github.com/Ghy0501/HiDe-LLaVA">Code</a>
              <br>
            </td>
          </tr>
	  
<!-- 	 <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/CVPR25_MambaIC.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">MambaIC: State Space Models for High-Performance Learned Image Compression</span>
              <br>
              <strong>Fanhu Zeng</strong>, Hao Tang, Yihua Shao, Siyu Chen, Ling Shao, Yan Wang
              <br>
              <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_MambaIC_State_Space_Models_for_High-Performance_Learned_Image_Compression_CVPR_2025_paper.html">Paper</a> / <a href="https://arxiv.org/abs/2503.12461">arXiv</a> / <a href="https://github.com/AuroraZengfh/MambaIC">Code</a>
              <br>
            </td>
          </tr> -->
		  
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ICLR25_Local-Prompt.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection</span>
              <br>
              <strong>Fanhu Zeng</strong>, Zhen Cheng, Fei Zhu, Hongxin Wei, Xu-Yao Zhang
              <br>
              <em>The Thirteenth International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025
              <br>
              <a href="https://openreview.net/forum?id=Ew3VifXaxZ">Paper</a> / <a href="https://arxiv.org/abs/2409.04796">arXiv</a> / <a href="https://github.com/AuroraZengfh/Local-Prompt">Code</a>
              <br>
            </td>
          </tr>
  	 
	  <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/NIPSW24_M2MTAG.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">M2M-TAG: Training-Free Many-to-Many Token Aggregation for Vision Transformer Acceleration</span>
              <br>
	       <strong>Fanhu Zeng</strong>, Deli Yu
              <br>
              <em>Workshop on Machine Learning and Compression, Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2024
              <br>
              <a href="https://openreview.net/forum?id=LO3Mw8Jrk0">Paper</a>
              <br>
            </td>
          </tr>

	  <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/MM25_EventVAD.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">EventVAD: Training-Free Event-Aware Video Anomaly Detection</span>
              <br>
               Yihua Shao, Haojin He, Sijie Li, Siyu Chen, Xinwei Long, <strong>Fanhu Zeng</strong>, Yuxuan Fan, Muyang Zhang, Ziyang Yan, Ao Ma, Xiaochen Wang, Hao Tang, Yan Wang, Shuyan Li
              <br>
	     <em> The 33rd ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2025
	      <br>
              <a href="https://arxiv.org/abs/2504.13092">arXiv</a> / <a href="https://github.com/YihuaJerry/EventVAD">Code</a>
              <br>
            </td>
          </tr>
		  
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ACL25_Chartedit.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs’ Capability via Chart Editing</span>
              <br>
               Xuanle Zhao*, Xuexin Liu*, Haoyue Yang*, Xianzhen Luo, <strong>Fanhu Zeng</strong>, Jianling Li, Qi Shi, Chi Chen
              <br>
              <em>Findings of the Association for Computational Linguistics (<strong>ACL</strong>)</em>, 2025
              <br>
              <a href="https://aclanthology.org/2025.findings-acl.185">Paper</a> / <a href="https://arxiv.org/abs/2505.11935">arXiv</a> / <a href="https://github.com/xxlllz/ChartEdit">Code</a>
              <br>
            </td>
          </tr>

          <!-- Preprints -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Preprints</h2>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!--/ Preprints -->

   	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Continual-learning-survey.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle"> A Comprehensive Survey on Continual Learning in Generative Models</span>
              <br>
               Haiyang Guo, <strong>Fanhu Zeng</strong>, Fei Zhu, Jiayi Wang, Xukai Wang, Jingang Zhou, Hongbo Zhao, Wenzhuo Liu, Shijie Ma, Da-Han Wang, Xu-Yao Zhang, Cheng-Lin Liu
              <br>
              <a href="https://arxiv.org/abs/2506.13045">arXiv</a> / <a href="https://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models">Code</a>
              <br>
            </td>
          </tr>
		  
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Position-token-reduction.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">Token Reduction Should Go Beyond Efficiency in Generative Models – From Vision, Language to Multimodality</span>
              <br>
               Zhenglun Kong*, Yize Li*, <strong>Fanhu Zeng</strong>, Lei Xin, Shvat Messica, Xue Lin, Pu Zhao, Manolis Kellis, Hao Tang, Marinka Zitnik
              <br>
              <a href="https://arxiv.org/abs/2505.18227">arXiv</a> / <a href="https://github.com/ZLKong/awesome-token-compression-reduction">Code</a>
              <br>
            </td>
          </tr>

   	 <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/TRDQ.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">TR-DQ: Time-Rotation Diffusion Quantization</span>
              <br>
               Yihua Shao, Deyang Lin, <strong>Fanhu Zeng</strong>, Minxi Yan, Muyang Zhang, Siyu Chen, Yuxuan Fan, Ziyang Yan, Haozhe Wang, Jingcai Guo, Yan Wang, Haotong Qin, Hao Tang
	      <br>
              <a href="https://arxiv.org/abs/2503.06564">arXiv</a>
              <br>
            </td>
          </tr>
            
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/FSMisD.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models</span>
              <br>
               <strong>Fanhu Zeng</strong>, Zhen Cheng, Fei Zhu, Xu-Yao Zhang
              <br>
              <a href="https://arxiv.org/abs/2503.20492">arXiv</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Merging.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">Parameter Efficient Merging for Multimodal Large Language Models with Complementary Parameter Adaptation</span>
              <br>
               <strong>Fanhu Zeng</strong>, Haiyang Guo, Fei Zhu, Li Shen, Hao Tang
              <br>
              <a href="https://arxiv.org/abs/2502.17159">arXiv</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/DESIRE.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">Dynamic Knowledge Consolidation for Rehearsal-Free Continual Learning</span>
              <br>
               Haiyang Guo, Fei Zhu, <strong>Fanhu Zeng</strong>, Bing Liu, Xu-Yao Zhang
              <br>
              <a href="https://arxiv.org/abs/2411.19154">arXiv</a>
              <br>
            </td>
          </tr>
		  
        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ModalPrompt.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">ModalPrompt: Dual-Modality Guided Prompt for Continual Learning of Large Multimodal Models</span>
              <br>
               <strong>Fanhu Zeng</strong>, Fei Zhu, Haiyang Guo, Xu-Yao Zhang, Cheng-Lin Liu
              <br>
              <a href="https://arxiv.org/abs/2410.05849">arXiv</a> / <a href="https://github.com/AuroraZengfh/ModalPrompt">Code</a>
              <br>
            </td>
          </tr>

	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/PPT.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <span class="papertitle">PPT: Token Pruning and Pooling for Efficient Vision Transformers</span>
              <br>
               Xinjian Wu, <strong>Fanhu Zeng</strong>, Xiudong Wang, Xinghao Chen
              <br>
              <a href="https://arxiv.org/abs/2310.01812">arXiv</a> / <a href="https://github.com/xjwu1024/PPT">Code</a>
              <br>
            </td>
          </tr>
            
        <!-- Academic Services -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Academic Services</h2>
                <p>
                  <li style="margin: 5px;"> 
                    <b>Conference Reviewer:</b>  EMNLP, NeurIPS, ICLR, CVPR, ICCV
                  </li>
                </p>
              </td>
            </tr>
          </tbody></table>
          <!--/ Academic Services -->

            
          <!-- template -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  <a href="https://github.com/jonbarron/jonbarron_website">Website Template</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          <!--/ template -->
        </td>
      </tr>
    </table>

    <p><center>
      <div id="clustrmaps-widget" style="width:5%">
        <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=uwrMhRzg_kEgyZHBCftBOeyYwONdPpFxttroJLaI_GQ"></script>
      </div>
      <br>
        &copy; Fanhu Zeng | Last updated: July, 2025
    </center></p>
  </body>
</html>
